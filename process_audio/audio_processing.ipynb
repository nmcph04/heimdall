{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data import preprocess_data\n",
    "\n",
    "features, (labels, labels_ohe), transformers = preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering and t-SNE for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering on the keystrokes\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Set k to the number of unique labels logged\n",
    "cluster_k = len(labels.unique())\n",
    "kmeans = KMeans(n_clusters=cluster_k, random_state=0, n_init=\"auto\").fit(features)\n",
    "\n",
    "print(f\"{cluster_k} clusters\")\n",
    "print('K-Means Clustering')\n",
    "print(f\"\\tSilhouette score: {silhouette_score(features, kmeans.labels_) :.2f}\")\n",
    "print('')\n",
    "\n",
    "#gmm = GaussianMixture(n_components=cluster_k, random_state=0)\n",
    "#gmm_predicted = gmm.fit_predict(features)\n",
    "#\n",
    "#print(\"Gaussian Mixture Model\")\n",
    "#print(f\"\\tSilhouette score: {silhouette_score(features, gmm_predicted) :.2f}\")\n",
    "#print('')\n",
    "#\n",
    "#spectral = SpectralClustering(n_clusters=cluster_k, random_state=0).fit(features)\n",
    "#\n",
    "#print(\"Spectral Clustering\")\n",
    "#print(f\"\\tSilhouette score: {silhouette_score(features, spectral.labels_) :.2f}\")\n",
    "#print('')\n",
    "\n",
    "# Get cluster predictions for each row\n",
    "predicted_clusters = []\n",
    "for _, keystroke in features.iterrows():\n",
    "    predicted_clusters.append(kmeans.predict(keystroke.array.reshape(1, -1)))\n",
    "\n",
    "predicted_clusters = np.array(predicted_clusters).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data with t-SNE dimensionality reduction to determine if the keystrokes make clusters\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sn\n",
    "\n",
    "def tsne_plot(data, labels=None):\n",
    "    model = TSNE(n_components = 2, random_state = 1)\n",
    "    # configuring the parameters\n",
    "    # the number of components = 2\n",
    "    # default perplexity = 30\n",
    "    # default learning rate = 200\n",
    "    # default Maximum number of iterations\n",
    "    # for the optimization = 1000\n",
    "    \n",
    "    tsne_data = model.fit_transform(data)\n",
    "    \n",
    "    # Colors points based on their label, if they have any\n",
    "    if labels is not None:\n",
    "        tsne_data = np.vstack((tsne_data.T, labels)).T\n",
    "        tsne_df = pd.DataFrame(data = tsne_data,\n",
    "           columns =(\"Dim_1\", \"Dim_2\", \"label\"))\n",
    "    \n",
    "        # Plotting the result of tsne\n",
    "        sn.scatterplot(data=tsne_df, x='Dim_1', y='Dim_2',\n",
    "                       hue='label', palette=\"bright\")\n",
    "    else:\n",
    "        tsne_df = pd.DataFrame(data = tsne_data,\n",
    "           columns =(\"Dim_1\", \"Dim_2\"))\n",
    "    \n",
    "        # Plotting the result of tsne\n",
    "        sn.scatterplot(data=tsne_df, x='Dim_1', y='Dim_2', palette=\"bright\")\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "    plt.title(\"t-SNE keystrokes\")\n",
    "    plt.show()\n",
    "\n",
    "tsne_plot(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Balance dataset with oversampling\n",
    "def oversample_datset(X, y):\n",
    "\n",
    "    oversample = RandomOverSampler()\n",
    "    over_X, over_y = oversample.fit_resample(X, y)\n",
    "    return over_X, over_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of each class\n",
    "unique_elements, counts = np.unique(np.array(labels), return_counts=True)\n",
    "count_of_elements = list(zip(unique_elements, counts))\n",
    "count_of_elements = sorted(count_of_elements, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "total_elements = counts.sum()\n",
    "\n",
    "print(\"Element: frequency of element\")\n",
    "for element, count in count_of_elements:\n",
    "    print(f\"{element}:\\t{count / total_elements * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = oversample_datset(features, labels)\n",
    "\n",
    "y = transformers['encoder'].transform(np.array(y).reshape(-1, 1)).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses GPU if available, otherwise uses CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "X_train = torch.tensor(X_train.to_numpy().astype(np.float32)).to(device)\n",
    "y_train = torch.tensor(y_train.astype(np.float32)).to(device)\n",
    "X_test = torch.from_numpy(X_test.to_numpy().astype(np.float32)).to(device)\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "hidden_size = [256, 128, 64] # Hidden layer sizes\n",
    "print(f'Input size: {input_size}\\nOutput size: {output_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear_sequential_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden_size[1], hidden_size[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden_size[2], output_size),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_sequential_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = Model(input_size, hidden_size, output_size).to(device)\n",
    "l = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "def getF1(pred_y: torch.Tensor, true_y: torch.Tensor):\n",
    "    pred_y = pred_y.cpu().detach().numpy()\n",
    "    pred_y = np.argmax(pred_y, axis=1)\n",
    "    \n",
    "    true_y = true_y.cpu().detach().numpy()\n",
    "    true_y = np.argmax(true_y, axis=1)\n",
    "\n",
    "    return f1_score(true_y, pred_y, average='macro')\n",
    "\n",
    "# Get accuracy\n",
    "def getAcc(pred_y: torch.Tensor, true_y: torch.Tensor):\n",
    "    pred_y = pred_y.cpu().detach().numpy()\n",
    "    pred_y = np.argmax(pred_y, axis=1)\n",
    "\n",
    "    true_y = true_y.cpu().detach().numpy()\n",
    "    true_y = np.argmax(true_y, axis=1)\n",
    "\n",
    "    num_values = np.float32(pred_y.shape[0])\n",
    "    num_correct = np.sum(pred_y == true_y)\n",
    "    \n",
    "    return num_correct / num_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1112)\n",
    "np.random.seed(1112)\n",
    "\n",
    "num_epochs = 10_000\n",
    "\n",
    "train_loss = [None]*num_epochs\n",
    "val_loss = [None]*num_epochs\n",
    "\n",
    "train_acc = [None]*num_epochs\n",
    "val_acc = [None]*num_epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    pred = model(X_train)\n",
    "    loss = l(pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss.item()\n",
    "    tr_acc = getAcc(pred, y_train)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    pred = model(X_test)\n",
    "    te_loss = l(pred, y_test).item()\n",
    "    te_acc = getAcc(pred, y_test)\n",
    "\n",
    "\n",
    "    train_loss[epoch] = tr_loss\n",
    "    val_loss[epoch] = te_loss\n",
    "    train_acc[epoch] = tr_acc\n",
    "    val_acc[epoch] = te_acc\n",
    "    if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "        print(f'Epoch {epoch+1} - train loss: {tr_loss :.4f} - val loss: {te_loss :.4f} - val acc: {te_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_trainhist = pd.DataFrame({'train_loss': train_loss, 'train_acc': train_acc, 'val_loss': val_loss, 'val_acc': val_acc, 'epoch': np.arange(num_epochs)})\n",
    "pt_trainhist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(\"Model Loss\")\n",
    "sns.lineplot(x='epoch', y='train_loss', data=pt_trainhist)\n",
    "sns.lineplot(x='epoch', y='val_loss', data=pt_trainhist)\n",
    "plt.legend(labels=['train_loss', 'val_loss'])\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(\"Model Accuracy\")\n",
    "sns.lineplot(x='epoch', y='train_acc', data=pt_trainhist)\n",
    "sns.lineplot(x='epoch', y='val_acc', data=pt_trainhist)\n",
    "plt.legend(labels=['train_acc', 'val_acc'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model predictions\n",
    "pred_idx_end = 50\n",
    "\n",
    "predictions = model(torch.tensor(X[:pred_idx_end].to_numpy().astype(np.float32)).to(device)).cpu().detach().numpy()\n",
    "pred_y = transformers['encoder'].inverse_transform(predictions).squeeze()\n",
    "true_y = transformers['encoder'].inverse_transform(y[:pred_idx_end]).squeeze()\n",
    "\n",
    "print(\"Predicted:\\tActual:\")\n",
    "for i in range(pred_idx_end):\n",
    "    print(f\"{pred_y[i]}\\t\\t{true_y[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(torch.tensor(X[0:1].to_numpy().astype(np.float32)).to(device)).cpu().detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heimdall2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
